---
title: "Foundations of Linear Models, Assignment 1"
author: Ayder Tanriver Ezgi (1541821), Oana Petrof (1541809), Olusoji Oluwafemi Daniel (1541893), Van Baelen Wessel (1234318)
  Owokotomo Olajumoke Evangelina (1539654)
date: "26 September 2016"
output:
  pdf_document: default
  fig_width: 4
  fig_height: 2
  fig_caption: true
---

```{r setup, include=FALSE,warning=FALSE,message=F}
knitr::opts_chunk$set(echo = FALSE, comment = NA,warning=FALSE,message=F,fig.height = 5)
library(markdown)
library(knitr)
library(xtable)
library(hwriter)
library(dplyr)
library(magrittr)
library(purrr)
library(readr)
```

## Problem 1

```{r}
mat1 <- matrix(data=c(1,0,1,0,2,2,1,2,3),nrow=3,ncol=3,byrow=T)
#kable(mat1,format='markdown',row.names = F, col.names=rep('',3))
```

###(i) Is the matrix of full rank?

Performing elementary row reduction on $A = \begin{bmatrix}
1 & 0 & 1\\
0 & 2 & 2\\
1 & 2 & 3
\end{bmatrix}$

$$\begin{matrix}
\\
\xrightarrow{r_2/2}\\
\xrightarrow{r_3 - r_1}
\end{matrix} \begin{bmatrix}
1 & 0 & 1\\
0 & 1 & 1\\
0 & 2 & 2
\end{bmatrix}$$

$$\begin{matrix}
\\
\\
\xrightarrow{r_3 - 2r_1}
\end{matrix} \begin{bmatrix}
1 & 0 & 1\\
0 & 1 & 1\\
0 & 0 & 0
\end{bmatrix}$$

and counting the number of non-zero rows gives a rank of 2. Also, computing the determinant of the matrix $A$,

$$1\left|\begin{array}{cc}
2 & 2\\
2 & 3
\end{array}\right| - 0\left|\begin{array}{cc}
0 & 2\\
1 & 3
\end{array}\right| + 1\left|\begin{array}{cc}
0 & 1\\
0 & 2
\end{array}\right| = 0 $$

The two approach showed that the matrix is not of full rank since the matrix has $rank =$ `r qr(mat1)$rank` which does not span the maximum space in dimension, which is 3. Also, the determinant of the matrix is `r det(mat1)` which implies that one of the rows of the matrix is linearly dependent on another row (row3 = row2 + 1), leading to the same conclusion that the matrix is not of full rank.

###(ii) Determine the eigenvalues and eigenvectors

To obtain the eigen values of the matrix $A$, the equation $|A - \lambda I_{3}| = 0$ is solved. $\lambda$ is scalar and $I_{3}$ is a $(3 \times 3)$ identity matrix and $0$ is a $(3 \times 1)$ column vector. Solving the system;

$$\left|\begin{array}{ccc}
1 & 0 & 1\\
0 & 2 & 2\\
1 & 2 & 3
\end{array} - \begin{array}{ccc}
\lambda & 0 & 0\\
0 & \lambda & 0\\
0 & 0 & \lambda
\end{array}\right| = 0$$

results into the equation $\lambda (6\lambda - \lambda^2 - 6)= 0$ which results in the roots $0$, $3 + \sqrt{3}$ and $3 - \sqrt{3}$. Therefore, the eigen values of the matrix are; `r round(eigen(mat1)$values,3)` and solving the system $(A - \lambda I_3)X = 0$ for each lambda gives the eigen vectors which are;

$$(0.5774, 0.5774, -0.5774) \ \ \ \text{for} \ \ \ 0$$,
$$ (0.2114, 0.5774, 0.7887)  \ \ \ \text{for}  \ \ \ 3 + \sqrt{3}$$ and
$$(0.7887, -0.5774, 0.2114)  \ \ \ \text{for}  \ \ \ 3 - \sqrt{3}$$.


```{r} 
#kable(eigen(mat1)$vectors,format='markdown',row.names = F,col.names = rep('',3))
```

Since the determinant of the matrix is 0 and it is as well symmetric, the product of the eigen values should be 0, i.e. $\prod_{i=1}^{3} \lambda_{i} = 0$ and the sum of the eigen values should give 6 (trace of the matrix), i.e. $\sum_{i=1}^{3} \lambda_{i} = 6$. $0 \times (3 + \sqrt{3}) \times (3 - \sqrt{3}) = 0$ and $0 + (3 + \sqrt{3}) + (3 - \sqrt{3}) = 6$ which validates lemma 2(i).

###(iii) Check for the validity of Lemma 2(iii)

Lemma 2(iii) is valid if $UDU^{-1} = A$ where $U$ is the eigen vector of the matrix A, $U^{-1}$ is the inverse of the eign vectors of the matrix A and D is a diagonal matrix of the eigenvalues of A.  $$U = \left( \begin{array}{ccc}
0.2113 & 0.7887 & 0.5774\\
0.5774 & -0.5774 & 0.5774\\
0.7887 & 0.2113  & -0.5774
\end{array} \right)$$
$$D = \left( \begin{array}{ccc}
4.732 & 0.000 & 0.000\\
0.000 & 1.268 & 0.000\\
0.000 & 0.000 & 0.000
\end{array} \right)$$ and $$U^{-1} = \left( \begin{array}{ccc}
0.2113 & 0.5774 & 0.7887\\
0.7887 & -0.5774 & 0.2113\\
0.5774 & 0.5774 & -0.5774
\end{array} \right)$$

Multiplying the matrix, gives;

$$\left( \begin{array}{ccc}
0.2113 & 0.7886751 & 0.5774\\
0.5774 & -0.5773503 & 0.5774\\
0.7887 & 0.2113  & -0.5774
\end{array} \right) \times \left( \begin{array}{ccc}
4.732 & 0.000 & 0.000\\
0.000 & 1.268 & 0.000\\
0.000 & 0.000 & 0.000
\end{array} \right) \times \left( \begin{array}{ccc}
0.2113 & 0.5774 & 0.7887\\
0.7887 & -0.5774 & 0.2113\\
0.5774 & 0.5774 & -0.5774
\end{array} \right)$$

The result of the multiplication gives the matrix below which is exactly A, hence the Lemma holds.

```{r}
#kable(round(eigen(mat1)$vectors %*% diag(eigen(mat1)$values) %*% solve(eigen(mat1)$vectors),2),format='markdown',row.names = F,col.names = rep('',3))
```

###(iv) Check for the Validity of Lemma 2(iv)

rank(A) = number of nonzero eigenvalues. This lemma is true for the matrix in question as the number of non-zero eigen values is 2 which is the same as the rank of the matrix.

## Problem 2

$P = X (X'X)^{-1} X'$ is the orthogonal projection onto the column space of the design matrix which maps the vector of reponse values to the vector of the predicted values. $I_n - P$ is the orthogonal to the information contained in the design matrix. Both $P$ and $I_{n} - P$ gives the solution to the least square problem when the model matrix has linearly independent columns. Intuitively, $P$ projects the response into the plane, and it acts as an identity matrix to the design matrix $X$, since $PX = X(X'X)^{-1}X'X = X$ and $I_n - P$ on the other hand acts as a 0 matrix to X, since $(I_n - P)X = X - PX = X - X = 0$.


The property $(I_n - P)X = 0$ is also crucial to derivation of other theorem as it is used on **page 13**, **line 22** for **part III** of **theorem 5** to show that $\hat{\beta}$ and $MSE$ are independent and also on **page 14**, **line 8** for **part 4** of **theorem 5** to show that $\frac{(n-p)MSE}{\sigma^{2}} \sim \chi_{n-p}^{2}$.


## Problem 7

```{r}
hw1 <- read_table('./Data/APPENC01.txt',col_names = c('IDNUM','LOS', 'Age', 'IR', 'RCR', 'RCXR', 'NumOfBeds', 'MSA', 'Region', 'ADC', 'NumberOfNurses', 'AFAS'))
hw11 <- hw1 %>% select(LOS,Age,IR,NumOfBeds,AFAS)
#hw11 %>% select(-LOS) %>% map(stem)
```
### Correlation Matrix

The correlation matrix for the model $LOS_1 = \beta_0 + \beta_1Age_1 + \beta_2IR_1 + \beta_3AFAS_1 + \epsilon_1$ is;

$$\begin{array}{c|cccc}
 & LOS & Age & IR & AFAS\\
 \hline
LOS & 1.00000 & 0.18891 & 0.53344 & 0.35554\\
 &  & (0.0451) & (<.0001) & (0.0001)\\
 \hline
Age & 0.18891 & 1.00000 & 0.00109 & -0.04045\\
 & (0.0451) &  & (0.9908) & (0.6705)\\
 \hline
IR & 0.53344 & 0.00109 & 1.00000 & 0.41260 \\
 & (<.0001) & (0.9908) &  & (<.0001)\\
 \hline
 AFAS & 0.35554 & -0.04045 & 0.41260 & 1.00000 \\
 & (0.0001) &  (0.6705) & (<.0001) &
\end{array}$$

while that of the model $LOS_1 = \beta_0 + \beta_1NumofBeds_1 + \beta_2IR_1 + \beta_3AFAS_1 + \epsilon_1$ is;

$$\begin{array}{c|cccc}
 & LOS & NumofBeds & IR & AFAS\\
 \hline
LOS & 1.00000 & 0.40927 & 0.53344 & 0.35554\\
 &  & (0.0451) & (<.0001) & (0.0001)\\
 \hline
NumofBeds & 0.40927 & 1.00000 & 0.35977 & 0.79452\\
 & (<.0001) &  & (<.0001) & (<.0001)\\
 \hline
IR & 0.53344 & 0.35977 & 1.00000 & 0.41260 \\
 & (<.0001) & (<.0001) &  & (<.0001)\\
 \hline
 AFAS & 0.35554 & 0.79452 & 0.41260 & 1.00000 \\
 & (0.0001) &  (0.79452) & (<.0001) &
\end{array}$$


## Appendix (Graphs & SAS Code)

### SAS Codes

#### Codes for Question 1

PROC IML;

*DEFINE THE MATRIX WHICH IS A IN THIS CASE;
	A={1 0 1,
	   0 2 2,
	   1 2 3};
	   
RANKOFMATRIX =ROUND(TRACE(GINV(A)*A)); *GETTING THE RANK OF THE MATRIX;

DETERMI = DET(A); *DETERMINANT OF MATRIX A;

EVECTOR = EIGVEC(A); *GETTING THE EIGEN VECTOR;

EVALUE = EIGVAL(A);   *GETTING THE EIGEN VALUE;

INVEVECTOR = INV(EVECTOR); *GETTING THE INVERSE OF THE EIGENVECTOR;

DIAGONALEVALUE = DIAG(EVALUE); *CONVERTING THE EIGEN VALUE TO DIAGONAL MATRIX;

ORIGINALMATRIX = EVECTOR * DIAGONALEVALUE * INVEVECTOR; *TESTING THE LEMMA 2(IV) IN THE TEXTBOOK;

PRINT RANKOFMATRIX DETERMI EVALUE EVECTOR INVEVECTOR DIAGONALEVALUE 

ORIGINALMATRIX;

QUIT;

#### Codes for Question 7

DATA SENIC;

infile `"C:\Users\OODOOE\Downloads\Video\Second Year\`

`First Semester\Foundation\foundation_assignment1\Data\APPENC01.txt"`;

input IDNUM LOS Age IR RCR RCXR NumOfBeds MSA Region ADC NumberOfNurses AFAS;

label LOS='Length of Patient Stay'

	  Age='Age of patients'
	  
	  IR='Infection Risk'
	  
	  AFAS='Available Facilities and Services'
	  
	  NumOfBeds='Number of Beds';
	  
run;

data hw1;

set SENIC;

keep IDNUM LOS Age NumOfBeds IR AFAS;

run;

*Scatter plot for each of the predictor variables;

title 'Stem and Leaf Plot';

ods listing;

ods graphics off;

ods select Plots SSPlots;

proc univariate data=Senic plot;

   var Age IR AFAS NumofBeds;

run;

title;

*Scatter Plot and Correlation Matrix for Model 1;

title 'Correlation Matrix and Scatter Plots for Model 1';

ods graphics on;

proc corr data=Senic plots=matrix(histogram);

var LOS Age IR AFAS;

run;

ods graphics off;

title;

*Scatter Plot and Correlation Matrix for Model 2;

title 'Correlation Matrix and Scatter Plots for Model 2';

ods graphics on;

proc corr data=Senic plots=matrix(histogram);

var LOS IR AFAS NumofBeds;

run;

ods graphics off;

title;

### Stem and Leaf Plot For Predictor Variables

![Age Stem and Leaf Plot](stemAge.PNG)


![Infectious Risk Stem and Leaf Plot](stemIR.PNG)


![Available Facilities and Services and Leaf Plot](stemAFAS.PNG)


![Available Facilities and Services and Leaf Plot](stemNumOfBeds.PNG)

\newpage

### Scatter Plots

![ScatterPlot for Model1](MatrixPlot.png)

![ScattePlot for Model2](MatrixPlot2.png)




